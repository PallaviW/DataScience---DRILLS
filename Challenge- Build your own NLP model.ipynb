{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "# Import the data we just downloaded and installed.\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "\n",
    "# Grab and process the raw data.\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw:\n",
      " [The Tragedie of Macbeth by William Shakespeare 1603]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Thunder and Lig\n"
     ]
    }
   ],
   "source": [
    "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "# Print the first 100 characters of shakespeare-macbeth.\n",
    "print('\\nRaw:\\n', macbeth[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning / Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "macbeth = text_cleaner(macbeth)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "macbeth_doc = nlp(macbeth)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Actus, Primus, .)</td>\n",
       "      <td>shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Scoena, Prima, .)</td>\n",
       "      <td>shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Thunder, and, Lightning, .)</td>\n",
       "      <td>shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Enter, three, Witches, .)</td>\n",
       "      <td>shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, .)</td>\n",
       "      <td>shakespeare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0            1\n",
       "0            (Actus, Primus, .)  shakespeare\n",
       "1            (Scoena, Prima, .)  shakespeare\n",
       "2  (Thunder, and, Lightning, .)  shakespeare\n",
       "3    (Enter, three, Witches, .)  shakespeare\n",
       "4                        (1, .)  shakespeare"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "macbeth_sents = [[sent, \"shakespeare\"] for sent in macbeth_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(macbeth_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_corpus = []\n",
    "macbeth_corpus = sentences[0]\n",
    "macbeth_corpus = np.array(macbeth_corpus)\n",
    "\n",
    "macbeth_new_corpus = []\n",
    "for item in macbeth_corpus:\n",
    "    macbeth_new_corpus.append(str(item))\n",
    "    \n",
    "macbeth_norm_corpus = []\n",
    "\n",
    "for doc in macbeth_new_corpus:\n",
    "    macbeth_norm_corpus.append(normalize_corpus(doc))\n",
    "    \n",
    "macbeth_norm_new_corpus = []\n",
    "for item in macbeth_norm_corpus:\n",
    "    macbeth_norm_new_corpus.append(item.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features creation using NLP methods\n",
    "### 1. BoW (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv =  CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(macbeth_norm_new_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "vocab = cv.get_feature_names()\n",
    "# show document feature vectors\n",
    "macbeth_cv_matrix = pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_cv_matrix\n",
    "macbeth_cv_matrix['text_sentence'] = sentences[0]\n",
    "macbeth_cv_matrix['text_source'] = sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = macbeth_cv_matrix['text_source']\n",
    "X = np.array(macbeth_cv_matrix.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9907352062163778\n",
      "\n",
      "Test set score: 0.9094982078853047\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90597015, 0.89387145, 0.89088191, 0.89536622, 0.89835575])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3346, 8054) (3346,)\n",
      "Training set score: 0.9856545128511656\n",
      "\n",
      "Test set score: 0.9413082437275986\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94029851, 0.94020927, 0.94170404, 0.92376682, 0.92376682])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW with GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8550508069336521\n",
      "\n",
      "Test set score: 0.842741935483871\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81044776, 0.83408072, 0.84304933, 0.82511211, 0.82959641])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW with LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9925283921099821\n",
      "\n",
      "Test set score: 0.9341397849462365\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "train = model.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', model.score(X_train, y_train))\n",
    "print('\\nTest set score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92537313, 0.93124066, 0.93273543, 0.92077728, 0.91330344])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3872\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "macbeth_norm_new_corpus_tfidf=vectorizer.fit_transform(macbeth_norm_new_corpus)\n",
    "print(\"Number of features: %d\" % macbeth_norm_new_corpus_tfidf.get_shape()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_matrix = macbeth_norm_new_corpus_tfidf.toarray()\n",
    "tfid_vocab = vectorizer.get_feature_names()\n",
    "# show document feature vectors\n",
    "macbeth_tfid_matrix = pd.DataFrame(tfid_matrix, columns=tfid_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_tfid_matrix['text_sentence'] = sentences[0]\n",
    "macbeth_tfid_matrix['text_source'] = sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = macbeth_tfid_matrix['text_source']\n",
    "X = np.array(macbeth_tfid_matrix.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.982068141063957\n",
      "\n",
      "Test set score: 0.8987455197132617\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', rfc.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90149254, 0.877429  , 0.89536622, 0.88938714, 0.86995516])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_train_tfidf, y_train_tfidf, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3346, 3872) (3346,)\n",
      "Training set score: 0.9497907949790795\n",
      "\n",
      "Test set score: 0.9081541218637993\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train_tfidf, y_train_tfidf)\n",
    "print(X_train_tfidf.shape, y_train_tfidf.shape)\n",
    "print('Training set score:', lr.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', lr.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9       , 0.89088191, 0.89686099, 0.86248132, 0.89835575])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train_tfidf, y_train_tfidf, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf with GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8475791990436342\n",
      "\n",
      "Test set score: 0.8445340501792115\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', clf.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81940299, 0.82959641, 0.82810164, 0.8161435 , 0.8161435 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train_tfidf, y_train_tfidf, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf with LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9748953974895398\n",
      "\n",
      "Test set score: 0.9332437275985663\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "train = model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "print('Training set score:', model.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', model.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91791045, 0.92376682, 0.92077728, 0.90284006, 0.92227205])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train_tfidf, y_train_tfidf, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have observed that BoW with Logistic Regression performed better compared to others while tfid with LinearSVC performed better compared to other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pick BoW with Logistic Regression as it gives best performance compared to other models after assessing cross validation score. Lets do some tunning to check if we can get some improved accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testset:\t0.9346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A parameter grid for LogisticRegression\n",
    "params = {'C':[1,10], 'penalty':['l1','l2']}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Initialize LogisticRegression and GridSearch\n",
    "grid = GridSearchCV(lr, params, cv=3)\n",
    "grid.fit(X_train_tfidf, y_train_tfidf)\n",
    "best_lr = grid.best_estimator_\n",
    "score = accuracy_score(y_true=y_test_tfidf, y_pred=best_lr.predict(X_test_tfidf))\n",
    "print('Accuracy on testset:\\t{:.4f}\\n'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92537313, 0.92526158, 0.92227205, 0.90433483, 0.92526158])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_val_score\n",
    "cross_val_score(best_lr, X_train_tfidf, y_train_tfidf, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "Data_lsa= lsa.fit_transform(X)\n",
    "# Split training testing data\n",
    "X_train_lsa, X_test_lsa, y_train_lsa, y_test_lsa = train_test_split(Data_lsa, Y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4183, 130) (4183,)\n",
      "Training set score: 0.9335405211570643\n",
      "\n",
      "Test set score: 0.9247311827956989\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train_lsa, y_train_lsa)\n",
    "print(X_train_lsa.shape, y_train_lsa.shape)\n",
    "print('Training set score:', lr.score(X_train_lsa, y_train_lsa))\n",
    "print('\\nTest set score:', lr.score(X_test_lsa, y_test_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91288783, 0.93548387, 0.9222488 , 0.91985646, 0.93301435])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train_lsa, y_train_lsa, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we have analyse the data above Bow with Logistic Regression worked very well and gave much better performance compared to applying LSA on the data.\n",
    "- As this shows that we are loosing information after performing LSA \n",
    "- Tfidf also worked well and LinearSVC is giving best permormance compared to other model with Tfidf data\n",
    "- So Logistic Regression is the better performing model with good cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
