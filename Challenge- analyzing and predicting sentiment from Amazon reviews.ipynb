{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_PATH = \"/home/ds/notebooks/datasets/reviews_Musical_Instruments_5.json\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "APP_NAME = \"Amazone Review Example\"\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "RF_NUM_TREES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "df = spark.read.options(inferschema = \"true\").json(json_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n",
      "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n",
      "|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n",
      "|1384719342|  [0, 0]|    5.0|Nice windscreen p...|02 14, 2014|A2C00NNG1ZQQG2|RustyBill \"Sunday...|GOOD WINDSCREEN F...|    1392336000|\n",
      "|1384719342|  [0, 0]|    5.0|This pop filter i...|02 21, 2014| A94QU4C90B1AX|       SEAN MASLANKA|No more pops when...|    1392940800|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|So good that I bo...|12 21, 2012|A2A039TZMZHH9Y| Bill Lewey \"blewey\"|      The Best Cable|    1356048000|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|I have used monst...|01 19, 2014|A1UPZM995ZAH90|               Brian|Monster Standard ...|    1390089600|\n",
      "|B00004Y2UT|  [0, 0]|    3.0|I now use this ca...|11 16, 2012| AJNFQI3YR6XJ5|   Fender Guy \"Rick\"|Didn't fit my 199...|    1353024000|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|Perfect for my Ep...| 07 6, 2008|A3M1PLEYNDEYO8|     G. Thomas \"Tom\"|         Great cable|    1215302400|\n",
      "|B00004Y2UT|  [0, 0]|    5.0|Monster makes the...| 01 8, 2014| AMNTZU1YQN1TH|         Kurt Robair|Best Instrument C...|    1389139200|\n",
      "|B00004Y2UT|  [6, 6]|    5.0|Monster makes a w...|04 19, 2012|A2NYK9KWFMJV4Y|Mike Tarrani \"Jaz...|One of the best i...|    1334793600|\n",
      "|B00005ML71|  [0, 0]|    4.0|I got it to have ...|04 22, 2014|A35QFQI0M46LWO|       Christopher C|It works great bu...|    1398124800|\n",
      "|B00005ML71|  [0, 0]|    3.0|If you are not us...|11 17, 2013|A2NIT6BKW11XJQ|                 Jai|HAS TO GET USE TO...|    1384646400|\n",
      "|B00005ML71|  [0, 0]|    5.0|I love it, I used...|06 16, 2013|A1C0O09LOLVI39|             Michael|             awesome|    1371340800|\n",
      "|B00005ML71|  [0, 0]|    5.0|I bought this to ...|12 31, 2012|A17SLR18TUMULM|         Straydogger|           It works!|    1356912000|\n",
      "|B00005ML71|  [0, 0]|    2.0|I bought this to ...|08 17, 2013|A2PD27UKAD3Q00|Wilhelmina Zeitge...|Definitely Not Fo...|    1376697600|\n",
      "|B000068NSX|  [0, 0]|    4.0|This Fender cable...|08 13, 2013| AKSFZ4G1AXYFC|        C.E. \"Frank\"|Durable Instrumen...|    1376352000|\n",
      "|B000068NSX|  [0, 0]|    5.0|wanted it just on...| 07 9, 2013| A67OJZLHBBUQ9|Charles F. Marks ...|fender 18 ft. Cal...|    1373328000|\n",
      "|B000068NSX|  [3, 3]|    5.0|I've been using t...|03 18, 2013|A2EZWZ8MBEDOLN|              Charlo|So far so good.  ...|    1363564800|\n",
      "|B000068NSX|  [0, 0]|    5.0|Fender cords look...| 08 7, 2013|A1CL807EOUPVP1|             GunHawk|Add California to...|    1375833600|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10261"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|         asin|           overall|          reviewText|reviewTime|          reviewerID|        reviewerName|             summary|      unixReviewTime|\n",
      "+-------+-------------+------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|        10261|             10261|               10261|     10261|               10261|               10234|               10261|               10261|\n",
      "|   mean|1.384719342E9| 4.488743787155248|                null|      null|                null|                null|                null|1.3606059557547998E9|\n",
      "| stddev|          0.0|0.8946423761647264|                null|      null|                null|                null|                null| 3.779735074639005E7|\n",
      "|    min|   1384719342|               1.0|                    |01 1, 2009|A00625243BI8W1SSZ...|\u001a\u001a\u001a\u001a\u001a\u001a\u001a \u001a\u001a\u001a\u001a\u001a \u001a\u001a\u001a...|\"As expected\" is ...|          1095465600|\n",
      "|    max|   B00JBIVXGC|               5.0|you will want thi...|12 9, 2013|       AZVME8JMPD3F4|              ~ Kyle|             yup yup|          1405987200|\n",
      "+-------+-------------+------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10234"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+-------+--------------+\n",
      "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|summary|unixReviewTime|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+-------+--------------+\n",
      "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|   good|    1393545600|\n",
      "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|   Jake|    1363392000|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+-------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overall|          reviewText|\n",
      "+-------+--------------------+\n",
      "|    5.0|Not much to write...|\n",
      "|    5.0|The product does ...|\n",
      "|    5.0|The primary job o...|\n",
      "|    5.0|Nice windscreen p...|\n",
      "|    5.0|This pop filter i...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('overall','reviewText').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRatingDecode(x):\n",
    "    if int(x) > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "func_udf = udf(calculateRatingDecode, IntegerType())\n",
    "df = df.withColumn('overall_encoded',func_udf(df['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------+\n",
      "|overall|          reviewText|overall_encoded|\n",
      "+-------+--------------------+---------------+\n",
      "|    5.0|Not much to write...|              1|\n",
      "|    5.0|The product does ...|              1|\n",
      "|    5.0|The primary job o...|              1|\n",
      "|    5.0|Nice windscreen p...|              1|\n",
      "|    5.0|This pop filter i...|              1|\n",
      "|    5.0|So good that I bo...|              1|\n",
      "|    5.0|I have used monst...|              1|\n",
      "|    3.0|I now use this ca...|              0|\n",
      "|    5.0|Perfect for my Ep...|              1|\n",
      "|    5.0|Monster makes the...|              1|\n",
      "|    5.0|Monster makes a w...|              1|\n",
      "|    4.0|I got it to have ...|              1|\n",
      "|    3.0|If you are not us...|              0|\n",
      "|    5.0|I love it, I used...|              1|\n",
      "|    5.0|I bought this to ...|              1|\n",
      "|    2.0|I bought this to ...|              0|\n",
      "|    4.0|This Fender cable...|              1|\n",
      "|    5.0|wanted it just on...|              1|\n",
      "|    5.0|I've been using t...|              1|\n",
      "|    5.0|Fender cords look...|              1|\n",
      "+-------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('overall','reviewText','overall_encoded').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"tokenized_words\")\n",
    "tokenized = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     tokenized_words|\n",
      "+--------------------+\n",
      "|[not, much, to, w...|\n",
      "|[the, product, do...|\n",
      "|[the, primary, jo...|\n",
      "|[nice, windscreen...|\n",
      "|[this, pop, filte...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.select('tokenized_words').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "# Learn a mapping from words to Vectors.\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"tokenized_words\", outputCol=\"result\")\n",
    "model = word2Vec.fit(tokenized)\n",
    "\n",
    "word2Vec_result = model.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              result|\n",
      "+--------------------+\n",
      "|[0.13150993396765...|\n",
      "|[0.07757678634180...|\n",
      "|[-0.0373586639338...|\n",
      "|[-0.0377182355150...|\n",
      "|[0.02990736892180...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2Vec_result.select('result').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"overall_encoded\", outputCol=\"indexedLabel\").fit(word2Vec_result)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"result\", outputCol=\"indexedFeatures\", maxCategories=4).fit(word2Vec_result)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = word2Vec_result.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=500)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.112856\n",
      "Accuracy = 0.887144\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"tokenized_words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(20,[0,1,2,3,4,5,...|\n",
      "|(20,[0,1,2,3,4,5,...|\n",
      "|(20,[0,1,2,3,4,5,...|\n",
      "|(20,[0,1,3,4,5,6,...|\n",
      "|(20,[0,1,4,5,6,8,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select('features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"overall_encoded\", outputCol=\"indexedLabel\").fit(rescaledData)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(rescaledData)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = rescaledData.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=500)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.117591\n",
      "Accuracy = 0.882409\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(20,[0,1,2,3,4,5,...|\n",
      "|       0.0|         0.0|(20,[0,1,3,4,5,6,...|\n",
      "|       0.0|         0.0|(20,[1,2,3,4,5,6,...|\n",
      "|       0.0|         0.0|(20,[0,1,2,3,4,5,...|\n",
      "|       0.0|         0.0|(20,[0,1,3,4,7,8,...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.122849\n",
      "Accuracy = 0.877151\n",
      "GBTClassificationModel (uid=GBTClassifier_4c8687228e8791cacc1c) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(f\"Accuracy = {accuracy:g}\")\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can observed word2Vec performed better compared to TF/IDF though difference is minimal \n",
    "- Random forest performing better if we tunned it by increasing number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
